{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('issue_commit_map_timestamp_filter.json', encoding=\"utf8\")\n",
    "issue_commit_map_timestamp_list = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['1341177539', '1338077710', '1338076041', '1331233264', '1331156614', '1329213467', '1315132643', '1301658893', '1301425818', '1291954110', '1290254053', '1258821091', '1254075498', '1253691977', '1248931625', '1247089417', '1246864988', '1246741758', '1246718021', '1244210329', '1236650008', '1236560436', '1236164350', '1236092796', '1217120376', '1203236055', '1164914971', '1164908492', '1125230714', '1090708193', '1088467065', '1084001171', '1078854826', '1070367702', '1064708221', '1063747831', '1063565003', '1063175036', '1063016909', '1062963320', '1052972339', '1052966204', '1052961349', '1052922082', '1052897315', '1047811253', '1047656491', '1047614223', '1034420159', '1015741953', '1015739319', '1011098721', '1007513145', '996663164', '992099703', '970099801', '964409705', '957483853', '950739075', '949371318', '946825651', '945403560', '945279969', '945276198', '945009001', '944968486', '930859358', '846056176', '846055370', '822370388', '822040848', '819741945', '813121209', '810324716', '807980866', '805280796', '805250549', '805148267', '804637512', '804209878', '802428272', '801523597', '800592790', '798233596', '798227542', '797970384', '797823473', '797820732', '797820236', '797809082', '797804050', '793891962', '777670835', '775245159', '774806725', '742941144', '740605141', '724838779', '720518089', '708300394'])\n"
     ]
    }
   ],
   "source": [
    "print(issue_commit_map_timestamp_list.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fix padding, Fix enabled parameter on switch settings, MatchFullscreen is false by default, Address comment, Match fullscreen to focus option, Add fullscreen option, Clean upHandle various build warnings and removing older classes, Update dependencies, Fix animation stutter, Re-add elevation and remove top content padding, Fix cover ContentScale, Fix expanded cover having a ratio and being rounded, NovelCard fixes, forced center alignment and outside padding, Fix scrolling filters, Add unread badge click, Licenses, Use a standard cover ratio, UI Cleanup and improvements, \n"
     ]
    }
   ],
   "source": [
    "# for issue_commit_map in issue_commit_map_timestamp_list.values():\n",
    "issue_title = issue_commit_map_timestamp_list[\"1331233264\"]['issue_title']\n",
    "commit_messages = issue_commit_map_timestamp_list['1331233264']['commit_messages']\n",
    "\n",
    "# print(commit_messages[0]['message'])\n",
    "list_of_commit = \"\"\n",
    "\n",
    "for commit in commit_messages:\n",
    "    list_of_commit+=commit['message']+', '\n",
    "\n",
    "\n",
    "list_of_commit = list_of_commit.replace(\"\\n\", \"\").replace(\"\\t\", \"\")\n",
    "\n",
    "print(list_of_commit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM MODEL STARTS HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OPENAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "m1 = \"sk-5GmSxGb0TLx6jzpzh\"\n",
    "m2 = \"FbhT3BlbkFJm3OoryQONwklze43ygTB\"\n",
    "OPENAI_API_KEY0 = m1+m2\n",
    "\n",
    "client = OpenAI(api_key=OPENAI_API_KEY0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt\n",
      " issue: Fullscreen Settings for Reader\n",
      "commit: Fix padding, Fix enabled parameter on switch settings, MatchFullscreen is false by default, Address comment, Match fullscreen to focus option, Add fullscreen option, Clean upHandle various build warnings and removing older classes, Update dependencies, Fix animation stutter, Re-add elevation and remove top content padding, Fix cover ContentScale, Fix expanded cover having a ratio and being rounded, NovelCard fixes, forced center alignment and outside padding, Fix scrolling filters, Add unread badge click, Licenses, Use a standard cover ratio, UI Cleanup and improvements, \n"
     ]
    }
   ],
   "source": [
    "prompt_sent_to_OPENAI = \"issue: \"+ issue_title + \"\\ncommit: \"+ list_of_commit\n",
    "print(\"prompt\\n\",prompt_sent_to_OPENAI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SINGLE ISSUE AND LIST OF COMMIT TRIALS\n",
    "\n",
    "command_to_OPENAI_to_check_similarity = \"You will receive two objects. One is an issue from gitHub. The other is a list of commit messages from gitHub where each commit is separated by a comma. Now assume and decide whether each of the commit message is refering to that issue and if the issue and commit message are related even indirectly then give output as 1 otherwise 0. So the final output is a string of 1s and 0s based on which commit is related to the issue in the given list of commits.  \\n For example , the input is given as issue: Fullscreen Settings for Reader \\ncommit: Fix padding, Fix enabled parameter on switch settings, MatchFullscreen is false by default, Address comment, Match fullscreen to focus option, Add fullscreen option, Clean up.. then the output is given as 1110111. \\nBecause address comment is not very much related to solving the issue about fullscreen settings.\\n Another example, the input is given as issue: Fullscreen Settings for Reader\\n commit: Handle various build warnings and removing older classes, Fix animation stutter, Re-add elevation and remove top content padding, Fix cover ContentScale, NovelCard fixes, Fix scrolling filters, Add unread badge click, Licenses, \\n then the output is given as 00100100. \\nBecause only two of them are related to the issue and the others are not related at all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "issue: Fullscreen Settings for Reader\n",
      "commit: Fix padding, Fix enabled parameter on switch settings, MatchFullscreen is false by default, Address comment, Match fullscreen to focus option, Add fullscreen option, Clean upHandle various build warnings and removing older classes, Update dependencies, Fix animation stutter, Re-add elevation and remove top content padding, Fix cover ContentScale, Fix expanded cover having a ratio and being rounded, NovelCard fixes, forced center alignment and outside padding, Fix scrolling filters, Add unread badge click, Licenses, Use a standard cover ratio, UI Cleanup and improvements, \n",
      "11101100110\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "model=\"gpt-3.5-turbo\",\n",
    "messages=[\n",
    "    {\"role\": \"system\", \"content\": command_to_OPENAI_to_check_similarity},\n",
    "    {\"role\": \"user\", \"content\": prompt_sent_to_OPENAI}\n",
    "]\n",
    ")\n",
    "\n",
    "print(prompt_sent_to_OPENAI)\n",
    "answer = completion.choices[0].message.content\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OPENAI THING ENDS HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM MODEL ENDS HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INDEPENDENT OF LLM STARTS AGAIN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# answer is the string of 1s and 0s which is received from the LLM model\n",
    "\n",
    "string_of_one_zero = answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'message': 'Fix padding', 'sha': '4a9e44d129f9ab16ac64544ae899c25699e673c8'}, {'message': 'Fix enabled parameter on switch settings', 'sha': 'd21f87b6de53afdbb5739a60e45a820c74c4f4f9'}, {'message': 'MatchFullscreen is false by default', 'sha': '44adc59f4aa4de17678ba69976ce8f79da17cecd'}, {'message': 'Match fullscreen to focus option', 'sha': '143552ab4769355e191ad302646cde95e71d6b28'}, {'message': 'Add fullscreen option', 'sha': '710f456e9c583b3ea681ce5df38f23c4f4e95d70'}, {'message': 'Fix animation stutter', 'sha': 'fe063724995199398ae07d2e2ff7635318466e58'}, {'message': 'Re-add elevation and remove top content padding', 'sha': 'c740328ac60e279f3838185fe2015660c8372381'}] \n",
      "\n",
      " [{'message': 'Address comment', 'sha': 'fedacb9ec5add798d58f8f3fd11741e0e9fb3b46'}, {'message': 'Clean up\\n\\nHandle various build warnings and removing older classes', 'sha': 'aeb6824afad9f88a34fb52521798838250d9f4a4'}, {'message': 'Update dependencies', 'sha': '8048ab61e03b0b5b8a39bd17b1294c5a3797f071'}, {'message': 'Fix cover ContentScale', 'sha': '3373a17ed53aa25cf36037adac0c84c290c2ca66'}]\n"
     ]
    }
   ],
   "source": [
    "filtered_related_commits = []\n",
    "filtered_unrelated_commits = []\n",
    "\n",
    "i=0\n",
    "for char in string_of_one_zero:\n",
    "    if(char=='1'):\n",
    "        filtered_related_commits.append(commit_messages[i])\n",
    "    else:\n",
    "        filtered_unrelated_commits.append(commit_messages[i])\n",
    "    \n",
    "    i+=1\n",
    "\n",
    "\n",
    "\n",
    "print(filtered_related_commits, '\\n\\n', filtered_unrelated_commits)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
